{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "generous-developer",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f3a6b4-52be-4c50-b7b0-9398867b68fb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-behalf",
   "metadata": {},
   "source": [
    "After training a model you need to be able to interact with in order to make predictions on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-morgan",
   "metadata": {},
   "source": [
    "Inference is a breeze with AIQC because it persists all of the information that we need to preprocess our new samples and reconstruct our model.\n",
    "\n",
    "Normally, the challenge with inference is being able to preprocess your new samples the same way as your processed your training samples. Additionally, if you provide labels with your new data for the purpose of evaluation, then PyTorch requires you to reconstruct parts of your model like your optimizer in order to calculate loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-blade",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "218c7aeb-7f00-4302-8465-a6bd78c67024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiqc import mlops, datum, tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-dependence",
   "metadata": {},
   "source": [
    "Below we're using AIQC's `tests.py` to quickly make a trained model so that we have examples to work with for making inference-based predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "persistent-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "queue_multiclass = tests.tf_multi_tab\n",
    "queue_multiclass.run_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-alberta",
   "metadata": {},
   "source": [
    "## Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-america",
   "metadata": {},
   "source": [
    "Let's say that we have a trained model in the form of a `Predictor`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "explicit-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = queue_multiclass.jobs[0].predictors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-premiere",
   "metadata": {},
   "source": [
    "and that we have samples that we want to generate predictions for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-signal",
   "metadata": {},
   "source": [
    "## New Splitset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "unsigned-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datum.to_pandas('iris.tsv').sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "automotive-sweden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width     species\n",
       "139           6.9          3.1           5.4          2.1   virginica\n",
       "86            6.7          3.1           4.7          1.5  versicolor\n",
       "21            5.1          3.7           1.5          0.4      setosa\n",
       "2             4.7          3.2           1.3          0.2      setosa\n",
       "44            5.1          3.8           1.9          0.4      setosa"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-leadership",
   "metadata": {},
   "source": [
    "We'll fashion a new `Splitset` of the samples that we want to predict using the high-level API.\n",
    "\n",
    "- Leave the `label_column` blank if you are conducting pure inference where you don't know the real Label/target. Otherwise, `splitset.label` will be used to generate metrics for your new predictions.\n",
    "- Ultimately, any splits that you make will be ignored when calling `infer()` below as all samples from the `Dataset` will be utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "impossible-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitset = mlops.Pipeline.Tabular(\n",
    "    df_or_path=df, label_column = 'species'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-october",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-things",
   "metadata": {},
   "source": [
    "Then pass that `Splitset` to `Predictor.infer()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-keeping",
   "metadata": {},
   "source": [
    "During `infer()`, it will validate that the schema of your new Splitset's `Feature` (the latest `Window` if provided) and `Label` (if provided) match the schema of the original training Splitset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-smoke",
   "metadata": {},
   "source": [
    "- `Dataset.Tabular` schema includes column ordering and dtype.\n",
    "- `Dataset.Image` schema includes Pillow size (height/width) and mode (color dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "extra-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predictor.infer(splitset_id=splitset.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-smell",
   "metadata": {},
   "source": [
    "If you encoded your Labels or generated unsupervised encoded data, don't worry, the output will be `inverse_transform`'ed as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "pretty-theta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'infer': array(['virginica', 'virginica', 'setosa', 'versicolor', 'setosa',\n",
       "        'virginica', 'versicolor', 'setosa', 'setosa', 'setosa'],\n",
       "       dtype=object)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-visit",
   "metadata": {},
   "source": [
    "For more information on the `Prediction` object, reference the [Low-Level API](api_low_level.html) documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "generous-developer",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-behalf",
   "metadata": {},
   "source": [
    "Down the road, you will need to make real-life predictions using the models that you've trained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-morgan",
   "metadata": {},
   "source": [
    "Inference is a breeze with AIQC because it persists all of the information that we need to preprocess our new samples and reconstruct our model.\n",
    "\n",
    "Normally, the challenge with inference is being able to preprocess your new samples the same way as your processed your training samples. Additionally, if you provide labels with your new data for the purpose of evaluation, then PyTorch requires you to reconstruct parts of your model like your optimizer in order to calculate loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-blade",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compressed-blend",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiqc\n",
    "from aiqc import datum\n",
    "from aiqc import tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-dependence",
   "metadata": {},
   "source": [
    "Below we're just making a trained model so that we have examples to work with for making inference-based predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "persistent-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "queue_multiclass = tests.make_test_queue('keras_multiclass')\n",
    "queue_multiclass.run_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-alberta",
   "metadata": {},
   "source": [
    "## Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-america",
   "metadata": {},
   "source": [
    "Let's say that we have a trained model in the form of a `Predictor`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "explicit-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = queue_multiclass.jobs[0].predictors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-premiere",
   "metadata": {},
   "source": [
    "and that we have samples that we want to generate predictions for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-signal",
   "metadata": {},
   "source": [
    "## New Splitset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unsigned-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datum.to_pandas('iris.tsv').sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "automotive-sweden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "29            4.7          3.2           1.6          0.2     setosa\n",
       "35            5.0          3.2           1.2          0.2     setosa\n",
       "40            5.0          3.5           1.3          0.3     setosa\n",
       "106           4.9          2.5           4.5          1.7  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-leadership",
   "metadata": {},
   "source": [
    "We'll fashion a new `Splitset` of the samples that we want to predict using the high-level API.\n",
    "\n",
    "- Leave the `label_column` blank if you are conducting pure inference where you don't know the real Label/target. Otherwise, `splitset.label` will be used to generate metrics for your new predictions.\n",
    "- Ultimately, any splits that you make will be ignored when calling `infer()` below as all samples from the `Dataset` will be utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "impossible-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitset = aiqc.Pipeline.Tabular.make(\n",
    "    dataFrame_or_filePath = df\n",
    "    , label_column = 'species'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-october",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-things",
   "metadata": {},
   "source": [
    "Then pass that `Splitset` to `Predictor.infer()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-keeping",
   "metadata": {},
   "source": [
    "During `infer()`, it will validate that the schema of your new Splitset's `Feature` (the latest `Window` if provided) and `Label` (if provided) match the schema of the original training Splitset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-smoke",
   "metadata": {},
   "source": [
    "- `Dataset.Tabular` schema includes column ordering and dtype.\n",
    "- `Dataset.Image` schema includes Pillow size (height/width) and mode (color dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "extra-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predictor.infer(splitset_id=splitset.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-smell",
   "metadata": {},
   "source": [
    "If you encoded your Labels or generated unsupervised encoded data, don't worry, the output will be `inverse_transform`'ed as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pretty-theta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'infer': array(['setosa', 'setosa', 'setosa', 'virginica', 'virginica',\n",
       "        'virginica', 'versicolor', 'virginica', 'versicolor', 'virginica'],\n",
       "       dtype=object)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-visit",
   "metadata": {},
   "source": [
    "For more information on the `Prediction` object, reference the [Low-Level API](api_low_level.html) documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

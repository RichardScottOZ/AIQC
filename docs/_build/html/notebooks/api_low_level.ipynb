{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-Level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've already completed the instructions on the **Installation** page, then let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiqc\n",
    "from aiqc import datum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ingest a `Dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Relational Model (ORM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Datasets](../images/dimensionality.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Dataset` class provides the following subclasses for working with different dimensionalities of data:\n",
    "\n",
    "- `Dataset.Tabular` - 2D constructed from either an array/dataframe or a tabular file.\n",
    "- `Dataset.Sequence` - 3D constructed from an array.\n",
    "- `Dataset.Image` - 4D constructed from either an array, a folder of files, or a list of URLs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During each stage of both the preprocessing and postprocessing pipelines, these shapes of data need to be handled differently. Additionally, each split and/or fold needs to be processed separately in order to avoid data leakage. You may also find yourself combining heterogenous featuresets (e.g. both tabular data and image data). All of these transformations needs to be recorded. The reason for this is that when making predictions during inference, the new samples must be processed identically to the original samples that the model was trained upon. Then these predictions must be decoded into their natural forms. AIQC coordinates all of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ingest:bool=True` parameter dictates whether or not the data is ingested into SQLite or if remains on disk and is accessed via `source_path`.\n",
    "\n",
    "By default the actual bytes of the file are persisted to the SQLite `BlobField`. It gets gzip compressed, reducing the size by up to 90%. Maximum BlobField size is 2.147 GB, but once you factor in compression, your bottleneck is more likely to be memory beyond that size. The bytes themselves are Parquet (single-partitioned) because, using the PyArrow engine, it preserves every dtype except certain datetimes (which are honestly better off parsed into floats/ ordinal ints). Parquet is also integrated nicely into both Spark and Dask; frameworks for distributed, in-memory computation.\n",
    "\n",
    "Persisting the file ensures reproducibility by: (a) keeping the data packaged alongside the experiment, and (b) helping entry-level users move away from relying on mutable dataframes they have had in-memory for extended periods of time or floating around on shared file systems.\n",
    "\n",
    "> *However, we realize that a different approach will be required at scale, so the `source_path` of the file is recorded whenever possible. In the future we could just read the data from that path (e.g. NFS, RDBMS, HDFS, S3) if the BlobField is none. Or just switch our data fetching/ filtering to Dask because it uses the Pandas API and Parquet.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Dataset.Tabular`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `from_pandas()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datum.to_pandas('iris.tsv')\n",
    "\n",
    "dataset = aiqc.Dataset.Tabular.from_pandas(\n",
    "\tdataframe = df\n",
    "    , name = 'tab separated plants'\n",
    "    , dtype = None #passed to pd.Dataframe(dtype)/ inferred\n",
    "    , column_names = None #passed to pd.Dataframe(columns)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Optionally, `dtype`, as seen in the `pandas.DataFrame.astype(dtype)` [docs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html), can be specified as either a single type for all columns, or as a dictionary that maps a specific type to each column name. This encodes features for analysis. We read NumPy into Pandas before persisting it, so `columns` and `dtype` are read directly by `pd.DataFrame()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `from_numpy()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Must be a 2D NumPy N-Dimensional Array.\n",
    "\n",
    "> *In the future, we may add support for ingesting 3D arrays as multi-file sequences.*\n",
    "\n",
    "Regular *ndarrays* don't have column names, and I didn't like the API for *structured arrays* so you have to pass in columns names as a list. If you don't then column names will be numerically assigned in ascending order (zero-based index), but I didn't like the range object, so I stringified numerically assigned columns to string-based numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr =  df.to_numpy()\n",
    "cols = list(df.columns)\n",
    "\n",
    "other_dataset = aiqc.Dataset.Tabular.from_numpy(\n",
    "\tndarray = arr\n",
    "    , column_names = cols #passed to pd.Dataframe(columns)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `from_path()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intended for flat files, delimited text, and structured tabular data. It's read in via Pandas, so it supports URLs to raw data and bytes as well.\n",
    "\n",
    "The `file_path` itself can be either absolute or relative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = datum.get_path('iris_10x.tsv')\n",
    "\n",
    "# We'll keep this larger dataset handy for `Foldset` creation later.\n",
    "big_dataset = aiqc.Dataset.Tabular.from_path(\n",
    "    file_path = file_path\n",
    "    , source_file_format = 'tsv'\n",
    "    , name = None\n",
    "    , dtype = None\n",
    "    , column_names = None\n",
    "    , skip_header_rows = 'infer' #passed to `pd.read_csv(header)`. Incompatible w Parquet.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you leave `name` blank, it will default to a human-readble timestamp with the appropriate file extension (e.g. '2020_10_13-01_28_13_PM.tsv')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Dataset.Sequence`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequence dataset is a 3 dimensional structure intended for multi-observations per sample to enable time series analysis. \n",
    "\n",
    "Observations must be ordered in an *ascending* manner, which means:\n",
    "\n",
    "- Time-based data must be ordered from earlier to later (2010 - 2020).\n",
    "- Position-based data must be ordered from beginning to end (start - stop)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence datasets are somewhat multi-modal in that, in order to perform supervised learning on them, they require a loosely coupled `Dataset.Tabular` that contains their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datum.to_pandas('epilepsy.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `['seizure']` column of this dataframe serves as the Label of that sample. We'll construct a `Dataset.Tabular` from this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_df = df[['seizure']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_tabular = aiqc.Dataset.Tabular.from_pandas(label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tabular_label = dataset_tabular.make_label(columns='seizure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `from_numpy()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`from_numpy(ndarray_3D:object)` requires a 3D NumPy array where each 2D array represents a sample. So we'll drop our seizure column from our DataFrame and reshape it into a 3D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_ndarray3D = df.drop(columns=['seizure']).to_numpy().reshape(1000,178,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚è±Ô∏è Validating Sequences üß¨: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 759287.47it/s]\n",
      "‚è±Ô∏è Ingesting Sequences üß¨: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:09<00:00, 105.99it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_sequence = aiqc.Dataset.Sequence.from_numpy(\n",
    "    ndarray_3D = seq_ndarray3D\n",
    "    , column_names = ['EEG']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_feature = dataset_sequence.make_feature()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skipping forward a bit, we bring the heterogenous `Feature` and `Label` together in the `Splitset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_splitset = aiqc.Splitset.make(\n",
    "    feature_ids = [sequence_feature.id]\n",
    "    , label_id = tabular_label.id\n",
    "    , size_test = 0.24\n",
    "    , size_validation = 0.12\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It is also possible to create a `Foldset` from this splitset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Dataset.Image`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image datasets are somewhat multi-modal in that, in order to perform supervised learning on them, they require a loosely coupled `Dataset.Tabular` that contains their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>size</th>\n",
       "      <th>count</th>\n",
       "      <th>symmetry</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://raw.githubusercontent.com/aiqc/aiqc/ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://raw.githubusercontent.com/aiqc/aiqc/ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://raw.githubusercontent.com/aiqc/aiqc/ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://raw.githubusercontent.com/aiqc/aiqc/ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://raw.githubusercontent.com/aiqc/aiqc/ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   status  size  count symmetry  \\\n",
       "0       0     0      0      NaN   \n",
       "1       0     0      0      NaN   \n",
       "2       0     0      0      NaN   \n",
       "3       0     0      0      NaN   \n",
       "4       0     0      0      NaN   \n",
       "\n",
       "                                                 url  \n",
       "0  https://raw.githubusercontent.com/aiqc/aiqc/ma...  \n",
       "1  https://raw.githubusercontent.com/aiqc/aiqc/ma...  \n",
       "2  https://raw.githubusercontent.com/aiqc/aiqc/ma...  \n",
       "3  https://raw.githubusercontent.com/aiqc/aiqc/ma...  \n",
       "4  https://raw.githubusercontent.com/aiqc/aiqc/ma...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = datum.to_pandas(name='brain_tumor.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `['status']` column of this dataframe serves as the Label of that sample. We'll construct a `Dataset.Tabular` from this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_dataset = aiqc.Dataset.Tabular.from_pandas(dataframe=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_label = tabular_dataset.make_label(columns=['status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `from_urls_pillow()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During ingestion, all image files must have the same `Image.mode` and `Image.size` according to the Pillow library.\n",
    "\n",
    "> https://pillow.readthedocs.io/en/stable/handbook/concepts.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`from_urls(urls:list)` needs a list of urls. In order to perform supervised learning, the order of this list must line up with the samples in your Tabular dataset.\n",
    "> We happen to have this list prepared in the `['url']` column of the dataframe above.  acts as a manifest in that it contains the URL of the image file for that sample, solely for the purposes of initial ingestion. We'll construct a `Dataset.Image` from this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_urls = datum.get_remote_urls(manifest_name='brain_tumor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è Validating Images üñºÔ∏è: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:14<00:00,  5.35it/s]\n",
      "üñºÔ∏è Ingesting Images üñºÔ∏è: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:07<00:00, 10.36it/s]\n"
     ]
    }
   ],
   "source": [
    "image_dataset = aiqc.Dataset.Image.from_urls_pillow(urls=image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_feature = image_dataset.make_feature()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skipping forward a bit, we bring the heterogenous `Feature` and `Label` together in the `Splitset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_splitset = aiqc.Splitset.make(\n",
    "    feature_ids = [image_feature.id]\n",
    "    , label_id = tabular_label.id\n",
    "    , size_test = 0.24\n",
    "    , size_validation = 0.12\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It is also possible to create a `Foldset` from this splitset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `from_folder_pillow()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When reading images from a locally accessible folder, the fantastic `natsort.natsorted` library is used as the source of truth for the order of the files.\n",
    "> Python reads files by insertion order rather than alpha-numerically, which isn't intuitive for humans. So make sure your tabular manifest has the same order as `natsorted`. https://natsort.readthedocs.io/en/master/api.html#natsort.natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è Validating Images üñºÔ∏è: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:00<00:00, 4041.00it/s]\n",
      "üñºÔ∏è Ingesting Images üñºÔ∏è: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:00<00:00, 209.31it/s]\n"
     ]
    }
   ],
   "source": [
    "image_dataset = aiqc.Dataset.Image.from_folder_pillow(\"/Users/layne/desktop/MRI_scans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see the first 3 files that comprise that dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<File: 85>, <File: 86>, <File: 87>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataset.files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_feature = image_dataset.make_feature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_splitset = aiqc.Splitset.make(\n",
    "    feature_ids = [image_feature.id]\n",
    "    , label_id = tabular_label.id\n",
    "    , size_test = 0.24\n",
    "    , size_validation = 0.12\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `from_numpy()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "Dataset.Image.from_numpy(\n",
    "        ndarray4D_or_npyPath:object\n",
    "        , name:str = None\n",
    "        , dtype:object = None\n",
    "        , column_names:list = None\n",
    "        , ingest:bool = True\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Datasets into Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the sample-related objects in the API have `to_numpy()` and `to_pandas()` methods that accept the following arguments:\n",
    "\n",
    "* `samples=[]` list of indices to fetch.\n",
    "* `columns=[]` list of columns to fetch.\n",
    "* In some cases you can specify a `split`/ `fold` name.\n",
    "\n",
    "For structured data, since the `Dataset` itself is fairly removed from the `File.Tabular` it creates, you can get that tabular file with `Dataset.Tabular.get_main_tabular(dataset_id)` to inspect attributes like `dtypes` and `columns`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later, we'll see how these arguments allow downstream objects like `Splitset` and `Foldset` to slice up the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Dataset.Tabular`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `to_pandas()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length  sepal_width\n",
       "0            5.1          3.5\n",
       "13           4.3          3.0\n",
       "29           4.7          3.2\n",
       "79           5.7          2.6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = aiqc.Dataset.to_pandas(\n",
    "    id = dataset.id \n",
    "    , samples = [0,13,29,79]\n",
    "    , columns = ['sepal_length', 'sepal_width']\n",
    ")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `to_numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4, 0.2],\n",
       "       [1.1, 0.1],\n",
       "       [1.6, 0.2],\n",
       "       [3.5, 1. ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = dataset.to_numpy(\n",
    "    samples = [0,13,29,79] \n",
    "    , columns = ['petal_length', 'petal_width']\n",
    ")\n",
    "arr[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2, 'setosa'],\n",
       "       [4.9, 3.0, 1.4, 0.2, 'setosa'],\n",
       "       [4.7, 3.2, 1.3, 0.2, 'setosa'],\n",
       "       [4.6, 3.1, 1.5, 0.2, 'setosa']], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = aiqc.Dataset.to_numpy(id=dataset.id)\n",
    "arr[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Dataset.Sequence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = dataset.to_numpy(\n",
    "    samples = [0] \n",
    "    , columns = None\n",
    ")\n",
    "arr[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `to_numpy()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This essentially internal method only exists to enable Pandas-related preprocessing such as interpolation. Produces a list of dataframes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `to_pandas()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This essentially internal method only exists to enable Pandas-related preprocessing such as interpolation. Produces a list of dataframes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `to_pillow()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This essentially internal method only exists to fetch images in their natural form (e.g. PNG/JPG)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Dataset.Image`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `to_pillow()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns a list of `PIL.Image`'s. You can actually see the image when you call them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=120x160 at 0x17BC66A00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_pillow = aiqc.Dataset.Image.to_pillow(id=image_dataset.id, samples=[60,61,62])\n",
    "images_pillow[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `to_numpy()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simply performs `np.array(Pillow.Image)`. Returns an N-dimensional array where the dimensions vary based on the `mode` aka colorscale of the image. For example, it returns '3D of 2Ds for black and white' or '4D of 3Ds for colored' - which would change the class of convultional layer you would use (`Conv1D`:`Conv3D`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> By default, the returned arrays will be scaled by 255 because [Pillow pixel values range from 0-255](https://pillow.readthedocs.io/en/stable/handbook/concepts.html#modes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out one of the 2D color channels of a grayscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04313725, 0.04313725, 0.04313725, ..., 0.07058824, 0.07058824,\n",
       "        0.07058824],\n",
       "       [0.01568627, 0.01568627, 0.01568627, ..., 0.07058824, 0.07058824,\n",
       "        0.07058824],\n",
       "       [0.        , 0.        , 0.        , ..., 0.07058824, 0.07058824,\n",
       "        0.07058824],\n",
       "       ...,\n",
       "       [0.07058824, 0.07058824, 0.07058824, ..., 0.07058824, 0.07058824,\n",
       "        0.07058824],\n",
       "       [0.07058824, 0.07058824, 0.07058824, ..., 0.07058824, 0.07058824,\n",
       "        0.07058824],\n",
       "       [0.07058824, 0.07058824, 0.07058824, ..., 0.07058824, 0.07058824,\n",
       "        0.07058824]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_pillow = aiqc.Dataset.Image.to_numpy(id=image_dataset.id, samples=[60,61,62])\n",
    "images_pillow[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Selecting `Features` and `Labels`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Select the `Label` column(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ORM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a Dataset, pick the column(s) that you want to predict/ train against. Creating a `Label` won't duplicate your data! It simply marks the Dataset `columns` to be used for supervised learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later, we'll see that a `Label` triggers:\n",
    "\n",
    "* The `supervision` attribute of a `Splitset` to be either `'unsupervised'`/`'supervised'`.\n",
    "\n",
    "* Approval/ rejection of the `Algorithm.analysis_type`. For example, you wouldn't perform regression on a string label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of the magic of this library is that it prevents you from making silly mistakes like these so that you aren't faced with some obscure NumPy/ Tensor, dtype/ dimensionality error on the nth layer of your neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For categorical labels, but not for continuous/float labels, the `Label.unique_classes` are recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deriving Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep the name of the label column handy as you may want to re-use it later when excluding features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = 'species'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implicit IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = dataset.make_label(columns=[label_column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `columns=[label_column]` is a list in case users have already OneHotEncoded (OHEd) their label. If multiple columns are provided, then they must already be in OHE format. I'm not keen on supporting multi-label/ simultaneous analysis, but that could changed based on feasibility and user demand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicit IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_label = aiqc.Label.from_dataset(\n",
    "\tdataset_id=other_dataset.id\n",
    "\t, columns=[label_column]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Label` comes in handy when we need to fetch what is traditionally referred to as '*Y*' in tutorials. It also accepts a `samples` argument, so that `Splitset` can subset it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       species\n",
       "145  virginica\n",
       "146  virginica\n",
       "147  virginica\n",
       "148  virginica\n",
       "149  virginica"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.to_pandas().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['setosa'],\n",
       "       ['setosa'],\n",
       "       ['versicolor'],\n",
       "       ['versicolor'],\n",
       "       ['virginica']], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.to_numpy(samples=[0,33,66,99,132])[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Select the `Feature` column(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ORM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Feature won't duplicate your data! It simply records the Dataset `columns` to be used as features during training. \n",
    "\n",
    "There are three ways to define which columns you want to use as features:\n",
    "\n",
    "- `exclude_columns=[]` for ruling out columns like the `Label` column.\n",
    "- `include_columns=[]` for being selective.\n",
    "- Leave both of the above blank and all columns will be used (e.g. images or unsupervised leanring)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For structured data, since the Feature is far removed from the `File.Tabular` that it is derived from, there is a `Feature.get_dtypes()` method. This will come in handy when we are selecting dtypes/columns to include/ exclude in our `Featurecoder`(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifying Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Via `include_columns=[]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = dataset.make_feature(\n",
    "    include_columns = [\n",
    "        'sepal_length',\n",
    "        'petal_length',\n",
    "        'petal_width'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or via `exclude_columns=[]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = dataset.make_feature(exclude_columns=[label_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal_length', 'sepal_width', 'petal_length', 'petal_width']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either way, any excluded columns will be recorded since they are used for dropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['species']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.columns_excluded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, for images, just perform `Dataset.Image.make_feature()` since you'll likely want to include all pixels and your label column is in a separate, coupled Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.to_numpy()[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length  sepal_width  petal_length  petal_width\n",
       "0            5.1          3.5           1.4          0.2\n",
       "16           5.4          3.9           1.3          0.4\n",
       "32           5.2          4.1           1.5          0.1\n",
       "64           5.6          2.9           3.6          1.3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.to_pandas(samples=[0,16,32,64]).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Slicing samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Define sliding time series `Windows`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ORM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Window` object is provided in order to facilitate sliding windows for unsupervised/ self-supervised time series forecasting and backcasting. It assumes that the last time point is the most recent (aka ascending time). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Windows](../images/sliding_windows.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concept of a sliding sample:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Dataset.Tabular` - The 'sample' is no longer a single image, but rather a group of images known as a window. Looking at the diagram above, there are 5 samples (*0:4* windows), not 15 samples (*0:14* time points)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Dataset.Sequence` - The 'sample' becomes a windowed sequence as opposed to an unwindowed sequence. Normally each sequence represents timesteps for a site/ patient. Windowing is applied to the timesteps within each sequence. That is to say that it groups rows within the sequence as windows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Dataset.Image` - The sample is no longer a single image, but rather a group of images known as a window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters:**\n",
    "- `size_window:int` the number of points in time to include in a window.\n",
    "- `size_shift:int` the number of points in time to slide forward.\n",
    "- `record_shift:bool=True` used during inference. Only persists unshifted windows and while leaving shifted windows as `None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifying Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`window = feature.make_window(size_window=4, size_shift=2)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `samples_unshifted:list of lists`\n",
    "- `samples_shifted:list of lists`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, `window.samples_unshifted[0]==[1,2,3,4]`. Where *1:4* represents the raw, underlying sample indices of that window. This is used when fetching the data. First, the entire `Feature` is fetched for preprocessing, then windows are copied out of it like so:\n",
    "\n",
    "- `np.array([feature_array[w] for w in window.samples_unshifted])`\n",
    "- `np.array([feature_array[w] for w in window.samples_shifted])`\n",
    "\n",
    "Where each of the above arrays is a 3D sequence that is fed into a single recurrent model. The shifted sequence is slotted into `samples[<split>]['labels']` to facilitate self-supervision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Slice samples with a `Splitset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Splitset` divides the samples of the Dataset into the following *splits* in the table below. It is the central object of the data preparation side of the ORM in that it touches `Label`, `Feature`, `Foldset`, and `Encoderset`. It is the only mandatory data preparation object required by the training `Queue`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both continuous and categorical `Labels` are automatically stratified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Split                 | Description                                                                                                                                                                                             |\n",
    "|-----------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| train                 | The samples that the model will be trained upon. <br/>Later, we‚Äôll see how we can make *cross-folds from our training split*. <br/>Unsupervised learning will only have a training split.                 |\n",
    "| validation (optional) | The samples used for training evaluation. <br/>Ensures that the test set is not revealed to the model during training.                                                                                  |\n",
    "| test (optional)       | The samples the model has never seen during training. <br/>Used to assess how well the model will perform on unobserved, natural data when it is applied in the real world aka how generalizable it is. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Label-based stratification is used to ensure equally distributed label classes for both categorical and continuous data.\n",
    ">\n",
    "> If you want more control over stratification of continuous splits, specify the number of `bin_count:int` for grouping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Again, creating a Splitset won't duplicate your data. It simply points to the sample indices to be used in the splits that you specify!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All tabular splits are stratified by default in that they contain similar distributions of unique Label classes so that each split is a statistically accurate representation of the population as a whole.\n",
    "\n",
    "In order to support this process for continuous labels, binning/ discretization is utilized. For example, if 4 bins are used, values from *0.0 to 1.0* would be binned as *[0.0-0.25, 0.25-0.50, 0.50-0.75, 0.75-1.0]*. This is controlled by the `bin_count:int` argument. \n",
    "\n",
    "> Reference the handy `Pandas.qcut()`  and the source code `pd.qcut(x=array_to_bin, q=bin_count, labels=False, duplicates='drop')` for more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally `unsupervised_stratify_column:str` is provided for scenarios where there is no Label. For example, you may want to stratify by the month during unsupervised time series analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `feature_ids:list` is plural. That's because we can pass a Splitset multiple Features for mixed-data analysis (e.g. using both Tabular and Image data). \n",
    "\n",
    "> If you have a feature that is capable of stratification (e.g. `dataset_type='tabular'` or `dataset_type='tabular'`), then you should make that `feature_id` the first element in the list. Only the first list element will be checked for the purposes of stratification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### i) Default supervised 70-30 split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a Label is provided, then a 70:30 train:test splits will automatically be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitset = aiqc.Splitset.make(\n",
    "    feature_ids = [feature.id]\n",
    "    , label_id=label.id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ii) Specifying test size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitset = aiqc.Splitset.make(\n",
    "    feature_ids = [feature.id]\n",
    "    ,label_id = label.id\n",
    "    , size_test = 0.22\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iii) Specifying validation size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`size_validation` cannot be specified without a `size_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitset = aiqc.Splitset.make(\n",
    "    feature_ids = [feature.id]\n",
    "    , label_id = label.id\n",
    "\t, size_test = 0.20\n",
    "\t, size_validation = 0.12\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iv) Unsupervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "    splitset = aiqc.Splitset.make(\n",
    "        label_id = None\n",
    "        , feature_ids = [feature.id]\n",
    "        , size_test=0.12\n",
    "        , size_validation=0.16\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### v) Take all samples for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "    splitset = aiqc.Splitset.make(\n",
    "        feature_ids = [feature.id]\n",
    "        , label_id = None # Optional for unsupervised and pure inference.\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "#### Reading Splitsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['validation', 'train', 'test'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitset.samples.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.keys()` of 1st layer are referred to as \"split_name\" in the source code: e.g. 'train' as well as, optionally, 'validation' and 'test'.\n",
    "  \n",
    "`Splitset.samples` on disk:\n",
    "```\n",
    " {\n",
    "     'train': [<sample_indices>],\n",
    "     'validation': [<sample_indices>],\n",
    "     'test': [<sample_indices>]\n",
    " }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also verify the actual size of your splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'validation': {'percent': 0.12, 'count': 18},\n",
       " 'test': {'percent': 0.2, 'count': 30},\n",
       " 'train': {'percent': 0.68, 'count': 102}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitset.sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main attribute of the splitset is the `samples` dictionary. Again, on-disk this only contains sample indices. The dictionary is structured like so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Create a `Foldset` for cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ORM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Reference the [scikit-learn documentation](https://scikit-learn.org/stable/modules/cross_validation.html) to learn more about folding.*\n",
    "\n",
    "![Cross Folds](../images/cross_fold.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We refer to the left out fold (blue) as the `fold_validation` and the remaining training data as the `folds_train_combined` (green)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *In the future, we may introduce more folding `strategies` aside from leave-one-out.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Fold` objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of determining which samples get trained upon, the only thing that matters is the slice of data that gets left out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tip - DO NOT use a `Foldset` unless your *(total sample count / fold_count)* still gives you an accurate representation of your sample population. If you are ignoring that advice and stretching to perform cross-validation, then at least ensure that *(total sample count / fold_count)* is evenly divisible. Both of these tips help avoid poorly stratified/ undersized folds that perform either too well (only most common label class present) or poorly (handful of samples and a few inaccurate prediction on a normally good model).\n",
    ">\n",
    "> Tip - The sample indices of the validation fold are not discarded. In fact, `fold_validation` can actually be used alongside a split `validation` for double validation ü§ò. However, it's more sensible to skip the validation split when cross-validating because you'll want each `fold_validation` to be as large (representative of the population) as possible. Folds naturally have fewer samples, so a handful of incorrect predictions have the potential to offset your aggregate metrics.\n",
    "> \n",
    "> Candidly, if you've ever performed cross-validation manually, let alone systematically, you'll know that, barring stratification of continuous labels, it's easy enough to construct the folds, but then it's a pain to generate performance metrics (e.g. `zero_division`, absent OHE classes) due to the absence of outlying classes and bins. Time has been invested to handle these scenarios elegantly so that folds can be treated as first-class-citizens alongside splits. That being said, if you try to do something undersized like \"150 samples in their dataset and a `fold_count` > 3 with `unique_classes` > 4,\" then you may run into edge cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to `Splitset.samples`, there is a `Fold.samples` dictionary of sample indices with the following `.keys()`:\n",
    "* `samples['folds_train_combined']` - all the included folds.\n",
    "* `samples['fold_validation']` - the fold that got left out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cross fold objects](../images/cross_fold_objects.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifying Foldsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll catch out big dataset up to the point where we can make a Foldset with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_label = big_dataset.make_label(columns=[label_column])\n",
    "big_fset = big_dataset.make_feature(exclude_columns=[label_column])\n",
    "big_splits = aiqc.Splitset.make(\n",
    "\tfeature_ids = [big_fset.id]\n",
    "    , label_id = big_label.id\n",
    "\t, size_test = 0.30\n",
    "    , bin_count=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to generate 5 `Fold` objects that belong to the `Foldset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldset = big_splits.make_foldset(fold_count=5, bin_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Fold: 1>, <Fold: 2>, <Fold: 3>, <Fold: 4>, <Fold: 5>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(foldset.folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Foldsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample indices of each Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foldset.folds[0].samples['folds_train_combined'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 20, 25, 29, 36, 44, 52, 53, 58, 59]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foldset.folds[0].samples['fold_validation'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessing - Interpolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have columns with missing data in a time series, then interpolation allows you to fill in those blanks mathematically. It does so by fitting a curve to each column. If you don't have time series data then you don't need interpolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `pandas.DataFrame.interpolate`\n",
    "> \n",
    "> https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.interpolate.html\n",
    "> \n",
    "> Is utilized due to its ease of use, variety of methods, and **support of sparse indices**. However, it does not follow the `fit/transform` pattern like many of the class-based sklearn preprocessors, so the interpolated training data is concatenated with the evalaution split during the interpolation of evaluation splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `interpolate_kwargs:dict=None` object is what gets passed to Pandas interpolation. In my experience, `method=spline` produces the best results. However, sometimes either spline cannot fit your data or you know that your pattern is linear. For those scenarios there's `method=linear`. \n",
    "\n",
    "Here the default argument that will ultimately be used in `df.interpolate(**interpolate_kwargs)` if `interpolate_kwargs=None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "interpolate_kwargs = dict(\n",
    "    method = 'spline'\n",
    "    , limit_direction = 'both'\n",
    "    , limit_area = None\n",
    "    , axis = 0\n",
    "    , order = 1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Interpolate Labels with `Labelpolater`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the fact that Labels cannot be windowed, Labelpolater simply fills in the gaps in a sequential progression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In scenarios where evaluation splits may not have enough data to be interpretted separately, there is the `process_separately:bool=False` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "label.make_labelpolater(\n",
    "    process_separately=True\n",
    "    , interpolate_kwargs=dict(\n",
    "        method='spline'\n",
    "        , limit_direction='both'\n",
    "        , limit_area=None\n",
    "        , axis=0\n",
    "        , order=1\n",
    "    )\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Interpolate Features with `Interpolaterset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![interpolate](../images/interpolate_windows.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that time series data is windowed presents challenges to preprocessing the training and evaluation splits/ folds separately in order to avoid leakage:\n",
    "\n",
    "- For 3D `Dataset.Sequence` interpolation is simply ran separately on each 2D array. \n",
    "- However, in 2D `Dataset.Tabular` different windows belong to different splits/ folds so their underlying groups of rows must be interpolated separately. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, there can be several columns/ dtypes in the data that have completely different patterns/ curves to fit. Thus we need a chain of `Featurepolaters` that is represented by `Interpolaterset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "interpolaterset = feature.make_interpolaterset()\n",
    "\n",
    "interpolaterset.make_featurepolater(\n",
    "    columns = ['nox']\n",
    "    , interpolate_kwargs = dict(\n",
    "        method='linear'\n",
    "        , limit_direction='both'\n",
    "        , limit_area=None\n",
    "        , axis=0\n",
    "        , order=1\n",
    "    )\n",
    ")\n",
    "\n",
    "interpolaterset.make_featurepolater(\n",
    "    dtypes = ['float64']\n",
    "    , interpolate_kwargs = dict(\n",
    "        method='spline'\n",
    "        , limit_direction='both'\n",
    "        , limit_area=None\n",
    "        , axis=0\n",
    "        , order=1\n",
    "    )\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocessing - Encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certain algorithms either (a) require features and/ or labels formatted a certain way, or (b) perform significantly better when their values are normalized. For example:\n",
    "\n",
    "* Scaling continuous features from (-1 to 1) or (0.0 to 1.0). Or transforming them to resemble a more Gaussian distribution.\n",
    "* Converting ordinal or categorical string data `[dog, cat, fish]` into one-hot encoded format `[[1,0,0][0,1,0][0,0,1]]`.\n",
    "\n",
    "There are two phases of encoding:\n",
    "1. `fit` - where the encoder learns about the values of the samples made available to it. Ideally, you only want to `fit` aka learn from your training split so that you are not *\"leaking\"* information from your validation and test spits into your encoder!\n",
    "2. `transform` - where the encoder transforms all of the samples in the population.\n",
    "\n",
    "AIQC has solved the following challenges related to encoding:\n",
    "\n",
    "* How does one dynamically `fit` on only the training samples in advanced scenarios like cross-validation where a different fold is used for validation each time?\n",
    "\n",
    "* For certain encoders, especially categorical ones, there is arguably no leakage. If an encoder is arbitrarilly assigning values/ tags to a sample through a process that is not aggregate-informed, then the information that is reveal to the `fit` is largely irrelevant. As an analogy, if we are examining swan color and all of a sudden there is a black swan... it's clearly not white, so slap a non-white label on it and move on. In fact, the prediction process and performance metric calucatlion may fail if it doesn't know how to handle the previously unseen category.\n",
    "\n",
    "* Certain encoders only accept certain dtypes. Certain encoders only accept certain dimensionality (e.g. 1D, 2D, 3D) or shape patterns (odd-by-odd square). Unfortunately, there is not much uniformity here.\n",
    "\n",
    "* Certain encoders output extraneous objects that don't work with deep learning libraries.\n",
    "\n",
    "> *For now, only `sklearn.preprocessing` methods are supported. That may change as we add support for more low-level tensor-based frameworks like PyTorch.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Encode labels with `Labelcoder`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplistic `Labelcoder` is a good warmup for the more advanced `Featurecoder`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, you cannot encode Labels if your `Splitset` does not have labels in the first place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process is straightforward. You provide an instantiated encoder [e.g. `StandardScaler()` not `StandardScaler`], and then AIQC will:\n",
    "\n",
    "* Verify that the encoder works with your `Label`'s dtype, sample values, and figure out what dimensionality it needs in order to succeed.\n",
    "\n",
    "* Automatically correct the attributes of your encoder to smooth out any common errors they would cause. For example, preventing the output of a sparse scipy matrix.\n",
    "\n",
    "* Determine whether the encoder should be `fit` either (a) exclusively on the train split, or (b) if it is not prone to leakage, inclusively on the entire dataset thereby reducing the chance of errors arising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a `Labelcoder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AIQC only supports the uppercase `sklearn.preprocessing` methods (e.g. `RobustScaler`, but not `robust_scale`) because the lowercase methods do not separate the `fit` and `transform` steps. FYI, most of the uppercase methods have a combined `fit_transform` method if you need them. \n",
    "\n",
    "> https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelcoder = label.make_labelcoder(\n",
    "    sklearn_preprocess = OneHotEncoder(sparse=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method is used behind the scenes to fetch the most recently create Labelcoder for your Label when it comes time to encode data during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labelcoder: 1>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.get_latest_labelcoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Encode Features sequentially with `Ensoderset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Featurecoder` has the same validation process as the `Labelcoder`. However, it is not without its own challenges:\n",
    "\n",
    "* We want to be able to apply different encoders to columns of different dtypes.\n",
    "\n",
    "* Additionally, even within the same dtype (e.g. float/ continuous), different distributions call for different encoders.\n",
    "\n",
    "* Commonly used encoders such a `OneHotEncoder` can ouput multiple columns from a single column input. Therefore, the *shape* of the features can change during encoding.\n",
    "\n",
    "* And finally, throughout this entire process, we need to avoid data leakage.\n",
    "\n",
    "For these reasons, `Featurecoder`'s are applied sequentially; in an ordered chain, one after the other. After an encoder is applied, its columns are removed from the raw feature and placed into an intermediary cache specific to each split/ fold. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Right now, `Featurecoder` cannot be created for `Dataset.Image.Feature`. I'm not opposed to changing this, but I would just have to account for 3D arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderset = feature.make_encoderset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering feature columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filtering mode is either:\n",
    "\n",
    "* Inclusive (`include=True`) encode columns that match the filter.\n",
    "\n",
    "* Exclusive (`include=False`) encode columns outside of the filter.\n",
    "\n",
    "Then you can select:\n",
    "\n",
    "1. An optional list of `dtypes`.\n",
    "\n",
    "2. An optional list of `columns` name.\n",
    "\n",
    "  * The column filter is applied after the dtype filter. \n",
    "  \n",
    "> You can create a filter for all columns by setting `include=False` and then seting both `dtypes` and `columns` to `None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submitting your encoder, if `verbose=True` is enabled:\n",
    "* The validation rules help determine why it may have failed.\n",
    "* The print statements help determine which columns your current filter matched, and which raw columns remain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "___/ featurecoder_index: 0 \\_________\n",
      "\n",
      "=> The column(s) below matched your filter(s) and were ran through a test-encoding successfully.\n",
      "\n",
      "['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "\n",
      "=> Done. All feature column(s) have encoder(s) associated with them.\n",
      "No more Featurecoders can be added to this Encoderset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurecoder = encoderset.make_featurecoder(\n",
    "    sklearn_preprocess = PowerTransformer(method='yeo-johnson', copy=False)\n",
    "    , include = True\n",
    "    , dtypes = ['float64']\n",
    "    , columns = None\n",
    "    , verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also view this information via the following attributes: `matching_columns`, `leftover_dtypes`, and `leftover_columns`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Preprocessing - Reshaping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with architectures that are highly dimensional such convolutional and recurrent networks (Conv1D, Conv2D, Conv3D / ConvLSTM1D, ConvLSTM2D, ConvLSTM3D), you'll often find yourself needing to reshape data to fit a layer's required input shape.\n",
    "\n",
    "- *Reducing unused dimensions* - When working with grayscale/ single channel images (1 channel * 25 rows * 25 columns) there is no sense using Conv2D just to handle that 1 channel.\n",
    "- *Adding wrapper dimensions* - Perhaps your data is a fit for ConvLSTM1D, but that layer is only supported in the nightly TensorFlow build so you want to add a wrapper dimension in order to use the production-ready ConvLSTM2D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is difficult do this on the fly during training (aka after the fact) because you need to: add reshaping layers/ views to your model, intercept and reshape the data in your post-processing functions, and, by this point, the data is in a variety of tensor formats. It's also more efficient to do this wrangling once up front rather than repeatedly on every training run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `reshape_indices` argument accepts a tuple for rearranging indices in your order of choosing. Behind the scenes, it will use `np.reshape()` to rearrange the data at the end of your preprocessing pipeline. How the element is handled in that tuple is determined by its type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`feature.make_featureshaper(reshape_indices:tuple)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# source code from the end of `feature.preprocess()`\n",
    "current_shape = feature_array.shape\n",
    "\n",
    "new shape = []\n",
    "for i in featureshaper.reshape_indices:\n",
    "    if (type(i) == int):\n",
    "        new_shape.append(current_shape[i])\n",
    "    elif (type(i) == str):\n",
    "        new_shape.append(int(i))\n",
    "    elif (type(i)== tuple):\n",
    "        indices = [current_shape[idx] for idx in i]\n",
    "        new_shape.append(math.prod(indices))\n",
    "new_shape = tuple(new_shape)\n",
    "            \n",
    "feature_array = feature_array.reshape(new_shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping by Index "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have a 4D feature consisting of 3D images `(samples * color channels * rows * columns)`. Our image is B&W, so we want to get rid of the single color channel. So we want to drop the dimension at the shape index `1`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "reshape_indices = (0,2,3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we have wrangled ourselves a 3D feature consisting of 2D images `(samples * rows * columns)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping Explicitly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if the dimensions we want cannot be expressed by rearranging the existing indices? You might have been wondering why `str` appeared in the loop above. If you define a string-based number, then that number will be used as the dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if I wanted to add an extra wrapper dimension to my data, I would simply do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "reshape_indices = (0,'1',1,2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplicative Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you need to stack/nest dimensions. This requires multiplying one shape index by another. For example, if I have a 3 separate hours worth of data and I want to treat it at 180 minutes, then I need to go from a shape of (3 hours * 60 minutes) to (180 minutes). Just provide the shape indices that you want to multiply in a `tuple` like so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "reshape_indices = ((0,1))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Defining Architectures & Hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Define an `Algorithm`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data has been prepared, we transition to the other half of the ORM where the focus is the logic that will be applied to that data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> An `Algorithm` is our ORM's codename for a machine learning model since *Model* is the most important *reserved word* when it comes to ORMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following attributes tell AIQC how to handle the Algorithm behind the scenes:\n",
    "\n",
    "* `library` - right now, only 'keras' is supported.\n",
    "\n",
    "  * Each library's model object and callbacks (history, early stopping) need to be handled differently.\n",
    "  \n",
    "  \n",
    "* `analysis_type` - right now, these types are supported:\n",
    "\n",
    "  * `'classification_multi'`, `'classification_binary'`, `'regression'`.\n",
    "  \n",
    "  * Used to determine which performance metrics to run.\n",
    "  \n",
    "  * Must be compatible with the type of label fed to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Algorithm` is composed of the functions:\n",
    "\n",
    "* `fn_build`.\n",
    "\n",
    "* `fn_lose` (optional, inferred).\n",
    "\n",
    "* `fn_optimize` (optional, inferred).\n",
    "\n",
    "* `fn_train`.\n",
    "\n",
    "* `fn_predict` (optional, inferred).\n",
    "\n",
    "> May provide overridable defaults for build and train in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can name the functions whatever you want, but do not change the predetermined arguments (e.g. `input_shape`,`**hp`, `model`, etc.) or their position.\n",
    "\n",
    "As we define these functions, we'll see that we can pass a dictionary of *hyperparameters* into these function using the `**hp` kwarg, and access them like so: `hp['<some_variable_name>']`. Later, we'll provide a list of values for each entry in the hyperparameters dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the modules that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import History\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Later, when running your `Job`'s, if you receive a \"module not found\" error, then you can try troubleshooting by importing that module directly within the function where it is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can build your topology however you like, just be sure to `return model`. Also, you don't have to use any of the hyperparameters (`**hp`) if you don't want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The automatically provided `features_shape` and `label_shape` are handy because:\n",
    "\n",
    "* The number of feature/ label columns is mutable due to encoders (e.g. OHE). \n",
    "\n",
    "* Shapes can be less obvious in multi-dimensional scenarios like colored images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can customize the metrics if you so desire (e.g. change the loss or accuracy), but they will only be applied to the training process/ `History` callback. We'll see later that AIQC will calculate metrics for you automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_build(features_shape, label_shape, **hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp['neuron_count'], input_shape=features_shape, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=hp['neuron_count'], activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(units=label_shape[0], activation='softmax'))\n",
    "    #optimizer and loss defined separately.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optional, function to calculate loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't just specify the loss function in our training loop because we will need it later on when it comes time to produce metrics about other splits/ folds.\n",
    "\n",
    "If you do not provide an `fn_lose` then one will be automatically selected for you based on the `Algorithm.analysis_type` you are conducting and the `Algorithm.library` you are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_lose(**hp):\n",
    "    loser = keras.losses.CategoricalCrossentropy()\n",
    "    return loser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optional, function to optimize model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some deep learning libraries persist their model and optimizer separately during checkpoint/exporting. So `fn_optimize` provides an isolated way to access the optimizer. It also allows us to automatically set the optimizer.\n",
    "\n",
    "If you do not provide an `fn_optimize` then one will be automatically selected for you based on the `Algorithm.analysis_type` you are conducting and the `Algorithm.library` you are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_optimize(**hp):\n",
    "    optimizer = keras.optimizers.Adamax(learning_rate=0.01)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you want to define your own optimizer, then you should do so within this function, rather than relying on `model.compile(optimizer='<some_optimizer_name>'`. If you do not define an optimizer, then `Adamax` will be used by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `samples_train` - the appropriate data will be fed into the training cycle. For example, `Foldset.samples[fold_index]['folds_train_combined']` or `Splitset.samples['train']`.\n",
    "\n",
    "* `samples_evaluate` - the appropriate data is made available for evaluation. For example, `Foldset.samples[fold_index]['fold_validation']`, `Splitset.samples['validation']`, or `Splitset.samples['test']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_train(model, loser, optimizer, samples_train, samples_evaluate, **hp):\n",
    "    model.compile(\n",
    "        loss = loser\n",
    "        , optimizer = optimizer\n",
    "        , metrics = ['accuracy']\n",
    "    )\n",
    "    model.fit(\n",
    "        samples_train[\"features\"]\n",
    "        , samples_train[\"labels\"]\n",
    "        , validation_data = (\n",
    "            samples_evaluate[\"features\"]\n",
    "            , samples_evaluate[\"labels\"]\n",
    "        )\n",
    "        , verbose = 0\n",
    "        , batch_size = 3\n",
    "        , epochs = hp['epoch_count']\n",
    "        , callbacks=[History()]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optional, callback to stop training early."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Early stopping* isn't just about efficiency in reducing the number of `epochs`. If you've specified 300 epochs, there's a chance your model catches on to the underlying patterns early, say around 75-125 epochs. At this point, there's also good chance what it learns in the remaining epochs will cause it to overfit on patterns that are specific to the training data, and thereby and lose it's simplicity/ generalizability.\n",
    "\n",
    "> The `val_` prefix refers to the evaluation samples.\n",
    ">\n",
    "> Remember, regression does not have accuracy metrics.\n",
    ">\n",
    "> `TrainingCallback.Keras.MetricCutoff` is a custom class we wrote to make multi-metric cutoffs easier, so you won't find information about it in the official Keras documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_train(model, loser, optimizer, samples_train, samples_evaluate, **hp):\n",
    "    model.compile(\n",
    "        loss = loser\n",
    "        , optimizer = optimizer\n",
    "        , metrics = ['accuracy']\n",
    "    )\n",
    "        \n",
    "    #Define one or more metrics to monitor.\n",
    "    metrics_cuttoffs = [\n",
    "        {\"metric\":\"val_accuracy\", \"cutoff\":0.96, \"above_or_below\":\"above\"},\n",
    "        {\"metric\":\"val_loss\", \"cutoff\":0.1, \"above_or_below\":\"below\"}\n",
    "    ]\n",
    "    cutoffs = aiqc.TrainingCallback.Keras.MetricCutoff(metrics_cuttoffs)\n",
    "    # Remember to append `cutoffs` to the list of callbacks.\n",
    "    callbacks=[History(), cutoffs]\n",
    "    \n",
    "    # No changes here.\n",
    "    model.fit(\n",
    "        samples_train[\"features\"]\n",
    "        , samples_train[\"labels\"]\n",
    "        , validation_data = (\n",
    "            samples_evaluate[\"features\"]\n",
    "            , samples_evaluate[\"labels\"]\n",
    "        )\n",
    "        , verbose = 0\n",
    "        , batch_size = 3\n",
    "        , epochs = hp['epoch_count']\n",
    "        , callbacks = callbacks\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optional, function to predict samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fn_predict` will be generated for you automatically if set to `None`. The `analysis_type` and `library` of the Algorithm help determine how to handle the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Regression default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_predict(model, samples_predict):\n",
    "    predictions = model.predict(samples_predict['features'])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Classification binary default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All classification `predictions`, both mutliclass and binary, must be returned in ordinal format. \n",
    "\n",
    "> For most libraries, classification algorithms output *probabilities* as opposed to actual predictions when running `model.predict()`. We want to return both of these object `predictions, probabilities` (the order matters) to generate performance metrics behind the scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_predict(model, samples_predict):\n",
    "    probabilities = model.predict(samples_predict['features'])\n",
    "    # This is the official keras replacement for binary classes `.predict_classes()`\n",
    "    # It returns one array per sample: `[[0][1][0][1]]` \n",
    "    predictions = (probabilities > 0.5).astype(\"int32\")\n",
    "    \n",
    "    return predictions, probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii) Classification multiclass default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_predict(model, samples_predict):\n",
    "    import numpy as np\n",
    "    probabilities = model.predict(samples_predict['features'])\n",
    "    # This is the official keras replacement for multiclass `.predict_classes()`\n",
    "    # It returns one ordinal array per sample: `[[0][2][1][2]]` \n",
    "    predictions = np.argmax(probabilities, axis=-1)\n",
    "    \n",
    "    return predictions, probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group the functions together in an `Algorithm`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = aiqc.Algorithm.make(\n",
    "    library = \"keras\"\n",
    "\t, analysis_type = \"classification_multi\"\n",
    "\t, fn_build = fn_build\n",
    "\t, fn_train = fn_train\n",
    "    , fn_optimize = fn_optimize # Optional\n",
    "\t, fn_predict = fn_predict # Optional\n",
    "\t, fn_lose = fn_lose # Optional\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <!> Remember to use `make` and not `create`. Deceptively,  `create` runs because it is a standard, built-in ORM method. However, it does so without any validation logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Combinations of hyperparameters with `Hyperparamset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters are fed into Algorithm functions.\n",
    "\n",
    "The `hyperparameters` below will be automatically fed into the functions above as `**kwargs` via the `**hp` argument we saw earlier.\n",
    "\n",
    "For example, wherever you see `hp['epoch_count']`, it will pull from the *key:value* pair `\"epoch_count\": [30, 60]` seen below. Where \"model A\" would have 30 epochs and \"model B\" would have 60 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "\t\"neuron_count\": [12]\n",
    "\t, \"epoch_count\": [30, 60]\n",
    "    , \"learning_rate\": [0.01, 0.03]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Selection Strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid search strategy.\n",
    "\n",
    "By default AIQC will generate all possible combinations.\n",
    "\n",
    "> With enough practice, practitioners will get a feel for what parameters and topologies make sense so you'll rely on shotgun-style approaches less and less. If you limit your experiments to 1-2 parameters at a time then it's easy to see their effect as an *independent variable*. You should really start with high-level things such as topologies (# of layers, # neurons per layer) and batch size before moving on to tuning the intra-layer nuances (activation methods, weight initialization). You're essentially testing high/ medium/ low or default/ edge case scenarios for each parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random selection strategy.\n",
    "\n",
    "Testing many different combinations in your initial runs can be a good way to get a feel for the parameter space. Although if you are doing this you'll find that many of your combinations are a bit too similar. So randomly sampling (with replacement) a few of them is a less computationally expensive way to go about this.\n",
    "\n",
    "* `pick_count:int` the fixed # of combinations to sample.\n",
    "\n",
    "* `pick_percent:float` a % of combinations to sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bayesian selection strategy.\n",
    "\n",
    "\"TPE (Tree-structured Parzen Estimator)\" via `hyperopt` has been suggested as a future area to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparamset = aiqc.Hyperparamset.from_algorithm(\n",
    "\talgorithm_id = algorithm.id\n",
    "\t, hyperparameters = hyperparameters\n",
    "    , pick_count = None\n",
    "    , pick_percent = None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Hyperparamcombo` objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each unique combination of hyperparameters is recorded as a `Hyperparamcombo`.\n",
    "\n",
    "Ultimately, a training `Job` is constructed for each unique combinanation of hyperparameters aka `Hyperparamcombo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparamset.hyperparamcombo_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neuron_count': 12, 'epoch_count': 30, 'learning_rate': 0.01}\n",
      "{'neuron_count': 12, 'epoch_count': 30, 'learning_rate': 0.03}\n",
      "{'neuron_count': 12, 'epoch_count': 60, 'learning_rate': 0.01}\n",
      "{'neuron_count': 12, 'epoch_count': 60, 'learning_rate': 0.03}\n"
     ]
    }
   ],
   "source": [
    "hyperparamcombos = hyperparamset.hyperparamcombos\n",
    "\n",
    "for h in hyperparamcombos:\n",
    "    print(h.hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neuron_count</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>epoch_count</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>learning_rate</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           param  value\n",
       "0   neuron_count  12.00\n",
       "1    epoch_count  30.00\n",
       "2  learning_rate   0.01"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparamcombos[0].get_hyperparameters(as_pandas=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. `Queue` of training `Jobs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Queue` is the central object of the \"logic side\" of the ORM. It ties together everything we need for training and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = aiqc.Queue.from_algorithm(\n",
    "\talgorithm_id = algorithm.id\n",
    "\t, splitset_id = splitset.id\n",
    "\t, hyperparamset_id = hyperparamset.id # Optional.\n",
    "\t, foldset_id = None # Optional.\n",
    "    , repeat_count = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `repeat_count:int` allows us to run the same `Job` multiple times. Normally, each `Job` has 1 `Predictor` associated with it upon completion. However, when `repeat_count` (> 1 of course) is used, a single `Job` will have multiple `Predictors`.\n",
    "\n",
    "> Due to the fact that training is a *nondeterministic* process, we get different weights each time we train a model, even if we use the same set of parameters. Perhaps you've have the right topology and parameters, but, this time around, the model just didn't recgonize the patterns. Similar to flipping a coin, there is a degree of chance in it, but the real trend averages out upon repetition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `hide_test:bool` excludes the test split from the performance metrics and visualizations. This avoids data leakage by forcing the user to make decisions based on the performance on their model on the training and evaluation samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) `Job` objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each `Job` in the Queue represents a `Hyperparamcombo` that needs to be trained.\n",
    "\n",
    "If a `Foldset` is used during `Queue` creation, then: \n",
    "\n",
    "- The number of jobs = `hyperparamcombo_count` * `fold_count`.\n",
    "- Each Job will have a `Fold`. Additionally, a superficial `Jobset` will be used to keep track of all Jobs related to that Foldset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Executing `Jobs`.\n",
    "\n",
    "There are two ways to execute a Queue of Jobs:\n",
    "\n",
    "#### i) `queue.run_jobs()`\n",
    "\n",
    "* Jobs are simply ran on a loop on the main *Process*.\n",
    "\n",
    "* Stop the Jobs with a keyboard interrupt e.g. `ctrl+Z/D/C` in Python shell or `i,i` in Jupyter.\n",
    "\n",
    "* It is the more reliable approach on Win/Mac/Lin.\n",
    "\n",
    "* Although this locks your main process (can't write more code) while models train, you can still fire up a second shell session or notebook.\n",
    "\n",
    "* Prototype your training jobs in this method so that you can see any errors that arise in the console.\n",
    "\n",
    "\n",
    "#### ii) DEPRECATED - `queue.run_jobs(in_background=True)`.\n",
    "\n",
    "*Support for background processing has not been restored after decoupling the preprocessing pipelines from the Queue/Job logic.*\n",
    "\n",
    "* The Jobs loop is executed on a separate, parallel `multiprocessing.Process`\n",
    "\n",
    "* Stop the Jobs with `queue.stop_jobs()`, which kills the parallel *Process* unless it already failed.\n",
    "\n",
    "* The benefit is that you can continue to code while your models are trained. There is no performance boost.\n",
    "\n",
    "* On Mac and Linux (Unix), `'fork'` multiprocessing is used (`force=True`), which allows us to display the progress bar. FYI, even in 'fork' mode, Python multiprocessing is much more fragile in Python 3.8, which seems to be caused by how pickling is handled in passing variables to the child process.\n",
    "\n",
    "* On Windows, `'spawn'` multiprocessing is used, which requires polling:\n",
    "\n",
    "  * `queue.poll_statuses()`\n",
    "  \n",
    "  * `queue.poll_progress(raw:bool=False, loop:bool=False, loop_delay:int=3)` where `raw=True` is just a float, `loop=True` won't stop checking jobs until they are all complete, and `loop_delay=3` checks the progress every 3 seconds. \n",
    "  \n",
    "* It is a known bug that the `aiqc.TrainingCallbacks.Keras.MetricCutoff` class does not work with `` as of Python 3.8.\n",
    "\n",
    "* Also, during stress tests, I observed that when running multiple queues at the same time, the SQLite database would lock when simultaneous writes were attempted.\n",
    "\n",
    "#### iii) Future, cluster execution.\n",
    "\n",
    "* In the future, we look to provide options for horizontal and vertical scale via either AWS or Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÆ Training Models üîÆ: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:48<00:00,  4.06s/it]\n"
     ]
    }
   ],
   "source": [
    "queue.run_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The queue is interuptable. You can stop the execution of a queue and resume it later.\n",
    "\n",
    "> This also comes in handy if either your machine or Python kernel either crashes or are interupted by accident. Whatever the reason, rest easy, just `run_jobs()` again to pick up where you left off. Be aware that the `tqdm` iteration time in the progress bar will be wrong because it will be divided by the jobs already ran."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing during Job is recorded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the execution of a Job, the latest Labelcoder and Encoderset(s) tied to the Label and Feature(s) of the Splitset used during training will record their `fit()` to the data.\n",
    "\n",
    "- `FittedLabelcoder` for the Labelcoder used.\n",
    "  - `fitted_encoders:object` to store the `fit`.\n",
    "- `FittedEncoderset` for each Feature used.\n",
    "  - `fitted_encoders:list` to store the `fit`(s).\n",
    "\n",
    "This process is critical for:\n",
    "\n",
    "- `inverse_transform()`'ing aka decoding predictions.\n",
    "- Encoding new data during inference exactly the same was as the samples that the model was trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes a lot of joins to fetch the fitted encoders after the fact. So these methods are used behind the scenes to make it a bit easier:\n",
    "\n",
    "- `Predictor.get_fitted_encoderset(job, label)`\n",
    "- `Predictor.get_fitted_labelcoder(job, feature)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) `Predictors` are the trained models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each `Job` trains a `Predictor`. The following attributes are automatically written to the `Predictor` after training.\n",
    "    \n",
    "* `model_file`: serialization varies for Keras and Pytorch deep learning framework.\n",
    "\n",
    "* `input_shapes`: used by `get_model()` during inference.\n",
    "\n",
    "* `history`: per epoch metrics recorded during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x175f17430>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_model = queue.jobs[0].predictors[0].get_model()\n",
    "compiled_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) `Predictions` are the output of a Predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you feed samples through a Predictor, you get Predictions. During training, Predictions are automatically generated for every split/fold that was tied to the Queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': {'accuracy': 0.8,\n",
       "  'f1': 0.7979797979797979,\n",
       "  'loss': 0.299685537815094,\n",
       "  'precision': 0.8055555555555555,\n",
       "  'recall': 0.8,\n",
       "  'roc_auc': 0.9700000000000001},\n",
       " 'validation': {'accuracy': 0.9444444444444444,\n",
       "  'f1': 0.9440559440559441,\n",
       "  'loss': 0.20146748423576355,\n",
       "  'precision': 0.9523809523809523,\n",
       "  'recall': 0.9444444444444444,\n",
       "  'roc_auc': 0.9814814814814815},\n",
       " 'train': {'accuracy': 0.9803921568627451,\n",
       "  'f1': 0.9803751803751803,\n",
       "  'loss': 0.09282194077968597,\n",
       "  'precision': 0.9814814814814815,\n",
       "  'recall': 0.9803921568627451,\n",
       "  'roc_auc': 0.9985582468281432}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue.jobs[0].predictors[0].predictions[0].metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `predictions`: dictionary of predictions per split/ fold. Values are `inverse_transform`'ed if Labels were encoded during training.\n",
    "\n",
    "* `probabilities`: dictionary of prediction probabilities per split/ fold. `None` for regression.\n",
    "\n",
    "* `metrics`: dictionary of metrics for each split/fold that vary based on the analysis_type.\n",
    "\n",
    "* `metrics_aggregate`: dictionary of average for each statistic across all splits/folds.\n",
    "\n",
    "* `plot_data`: metrics readily formatted for plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Metrics & Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on visualization of performance metrics, reference the [Visualization & Metrics](visualization.html) documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
